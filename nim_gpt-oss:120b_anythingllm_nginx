#!/usr/bin/env bash
set -Eeuo pipefail
trap 'echo "ERROR on line $LINENO: $BASH_COMMAND" >&2' ERR

echo "==================================================================="
echo " DGX Spark Setup: NIM (gpt-oss-120b) + AnythingLLM + HTTPS (nginx)"
echo "==================================================================="
echo
echo "To run NIM containers you need an NVIDIA NGC API key."
echo
echo "Create or manage your NVIDIA API key here:"
echo "  ðŸ‘‰  https://ngc.nvidia.com/setup/api-key"
echo
echo "Log in there, generate an API key if needed."
echo

# --- Check prerequisites ---
if ! command -v docker >/dev/null 2>&1; then
  echo "ERROR: docker is not installed or not in PATH."
  exit 1
fi

if ! docker compose version >/dev/null 2>&1 && ! command -v docker-compose >/dev/null 2>&1; then
  echo "ERROR: docker compose (v2: 'docker compose' or legacy 'docker-compose') is not installed."
  exit 1
fi

if ! command -v openssl >/dev/null 2>&1; then
  echo "ERROR: openssl is required to generate the TLS certificate and secrets. Install it, e.g.:"
  echo "  apt-get update && apt-get install -y openssl"
  exit 1
fi

# Decide which compose command to use
if docker compose version >/dev/null 2>&1; then
  DOCKER_COMPOSE_CMD="docker compose"
else
  DOCKER_COMPOSE_CMD="docker-compose"
fi

# --- Ask for NGC API key & validate with docker login in a loop ---
NGC_API_KEY=""
while :; do
  echo
  read -rsp "Enter your NVIDIA NGC API Key (input hidden): " NGC_API_KEY
  echo
  if [[ -z "${NGC_API_KEY}" ]]; then
    echo "API key cannot be empty. Please try again."
    continue
  fi

  echo "Testing NVIDIA registry login with the provided key..."
  set +e
  echo "${NGC_API_KEY}" | docker login nvcr.io -u '$oauthtoken' --password-stdin >/dev/null 2>&1
  LOGIN_STATUS=$?
  set -e

  if [[ ${LOGIN_STATUS} -eq 0 ]]; then
    echo "âœ… NVIDIA registry login successful."
    break
  else
    echo "âŒ Login failed. The key may be wrong, expired, or lacks registry access."
    read -rp "Try entering the key again? (y/N): " TRY_AGAIN
    TRY_AGAIN=${TRY_AGAIN:-n}
    if [[ ! "${TRY_AGAIN}" =~ ^[Yy]$ ]]; then
      echo "Aborting setup due to failed NVIDIA login."
      exit 1
    fi
  fi
done

# --- Determine hostname for TLS cert ---
HOST_FQDN="$(hostname -f 2>/dev/null || hostname)"
echo
echo "Using hostname '${HOST_FQDN}' for TLS certificate CN and nginx server_name."
echo

echo "Generating secure local secrets (NIM API key, JWT secret, AnythingLLM admin password)..."

# Use openssl rand for all secrets (no pipes/pipefail issues)
NIM_API_KEY="$(openssl rand -hex 64)"
JWT_SECRET="$(openssl rand -hex 64)"
ADMIN_PASSWORD="$(openssl rand -base64 32 | tr -dc 'A-Za-z0-9' | head -c 24)"

UID_VAL="$(id -u)"
GID_VAL="$(id -g)"

# --- Write .env ---
cat > .env <<EOF
# Auto-generated by setup_nim_anythingllm.sh
NGC_API_KEY=${NGC_API_KEY}
NIM_API_KEY=${NIM_API_KEY}
UID=${UID_VAL}
GID=${GID_VAL}
EOF

echo "Created .env"

# --- Write anythingllm.env ---
cat > anythingllm.env <<EOF
# Auto-generated by setup_nim_anythingllm.sh

# Password for AnythingLLM instance (used to log in as admin)
AUTH_TOKEN=${ADMIN_PASSWORD}

# Session / auth secret
JWT_SECRET=${JWT_SECRET}

# Storage path inside AnythingLLM container
STORAGE_DIR=/app/server/storage

# Use OpenAI-compatible provider, backed by local NIM
LLM_PROVIDER=openai
OPENAI_BASE_PATH=http://nim-gpt-oss-120b:8000/v1
OPENAI_API_KEY=${NIM_API_KEY}
OPENAI_MODEL_PREF=openai/gpt-oss-120b
EOF

echo "Created anythingllm.env"

# --- Generate self-signed TLS cert for nginx ---
echo "Generating self-signed TLS certificate for hostname '${HOST_FQDN}'..."
mkdir -p nginx/certs

openssl req -x509 -nodes -days 365 \
  -newkey rsa:4096 \
  -keyout nginx/certs/anythingllm.key \
  -out nginx/certs/anythingllm.crt \
  -subj "/CN=${HOST_FQDN}" >/dev/null 2>&1

echo "Created nginx/certs/anythingllm.key and .crt"

# --- Write nginx.conf ---
mkdir -p nginx
cat > nginx/nginx.conf <<EOF
user  nginx;
worker_processes  auto;

events {
    worker_connections  1024;
}

http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;
    sendfile      on;
    keepalive_timeout  65;

    # HTTP -> HTTPS redirect
    server {
        listen 80;
        server_name ${HOST_FQDN};
        return 301 https://\$host\$request_uri;
    }

    # HTTPS reverse proxy to AnythingLLM
    server {
        listen 443 ssl;
        server_name ${HOST_FQDN};

        ssl_certificate     /etc/nginx/certs/anythingllm.crt;
        ssl_certificate_key /etc/nginx/certs/anythingllm.key;

        ssl_protocols       TLSv1.2 TLSv1.3;
        ssl_ciphers         HIGH:!aNULL:!MD5;

        location / {
            proxy_pass http://anythingllm:3001;
            proxy_http_version 1.1;

            proxy_set_header Host \$host;
            proxy_set_header X-Real-IP \$remote_addr;
            proxy_set_header X-Forwarded-For \$proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto https;

            proxy_buffering off;
        }
    }
}
EOF

echo "Created nginx/nginx.conf"

# --- Write docker-compose.yml ---
cat > docker-compose.yml <<'EOF'
services:
  nim-gpt-oss-120b:
    image: nvcr.io/nim/openai/gpt-oss-120b:latest
    container_name: nim-gpt-oss-120b
    restart: unless-stopped
    # OpenAI-compatible NIM API; bound to localhost only
    ports:
      - "127.0.0.1:8000:8000"
    environment:
      NGC_API_KEY: ${NGC_API_KEY}
      NIM_API_KEY: ${NIM_API_KEY}
    shm_size: "16g"
    gpus: "all"
    networks:
      - llm-net

  anythingllm:
    image: mintplexlabs/anythingllm:latest
    container_name: anythingllm
    restart: unless-stopped
    cap_add:
      - SYS_ADMIN
    user: "${UID}:${GID}"
    environment:
      STORAGE_DIR: /app/server/storage
    env_file:
      - anythingllm.env
    volumes:
      - ./anythingllm_data:/app/server/storage
      - ./anythingllm.env:/app/server/.env
    networks:
      - llm-net

  nginx:
    image: nginx:alpine
    container_name: anythingllm-nginx
    restart: unless-stopped
    depends_on:
      - anythingllm
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/certs:/etc/nginx/certs:ro
    networks:
      - llm-net

networks:
  llm-net:
    driver: bridge
EOF

echo "Generated docker-compose.yml"

# --- Create data directory ---
mkdir -p anythingllm_data
echo "Ensured anythingllm_data/ directory exists"

# --- Show admin password & ask to start ---
echo
echo "==============================================="
echo " AnythingLLM admin password (AUTH_TOKEN):"
echo "   ${ADMIN_PASSWORD}"
echo "==============================================="
echo "âš ï¸  Save this somewhere secure. You'll need it to log in."
echo

read -rp "Start NIM + AnythingLLM + nginx now? (y/N): " START_NOW
START_NOW=${START_NOW:-n}

if [[ "${START_NOW}" =~ ^[Yy]$ ]]; then
  echo "Starting containers..."
  ${DOCKER_COMPOSE_CMD} up -d
  echo
  echo "===================================================================="
  echo " ðŸŽ‰ Deployment complete!"
  echo "--------------------------------------------------------------------"
  echo " NIM gpt-oss-120b API (local only):"
  echo "   http://127.0.0.1:8000/v1/chat/completions"
  echo
  echo " AnythingLLM via HTTPS (self-signed cert):"
  echo "   https://${HOST_FQDN}/"
  echo
  echo " Use the admin password shown above when prompted by AnythingLLM."
  echo "===================================================================="
else
  echo "Configuration complete. You can start the stack later with:"
  echo "  ${DOCKER_COMPOSE_CMD} up -d"
fi

echo
echo "Done. One script to rule them all. ðŸ§™â€â™‚ï¸"
